dim(vowel.train) # 528  11
dim(vowel.test) # 462  11
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
library(caret)
order(varImp(modelRf), decreasing=T)
trainData <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testData <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainData), na.strings=c("NA","#DIV/0!",""))
View(training)
testing <- read.csv(url(testData), na.strings=c("NA","#DIV/0!",""))
View(testing)
View(testing)
View(training)
data(iris)
library(ggplot2)
names(iris)
View(iris)
table(iris$species)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
library(caret)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training)
dim(testing)
qplot(Petal.Width, Sepal.Width, colour=Species, data=training)
modFit <-train(Species ~ ., method="rpart", data=training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE, main="Classification Tree")
text(modFit$finalModel, use.n = TRUE, all= TRUE, cex=.8)
library(rattle)
install.packages("rattle")
library(rattle)
trainData <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(modFit$finalModel)
library(caret)
library(rattle)
library(rpart)
library(randomForest)
set.seed(4545)
trainData <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testData <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainData), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testData), na.strings=c("NA","#DIV/0!",""))
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
theTraining <- training[inTrain, ]; theTesting <- training[-inTrain, ]
dim(theTraining); dim(theTesting)
modelFit <- train(Classe ~ ., method="rpart", data=theTraining)
View(theTraining)
modelFit <- train(classe ~ ., method="rpart", data=theTraining)
summary(theTraining)
library(caret)
library(rattle)
library(rpart)
set.seed(4545)
trainData <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testData <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainData), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testData), na.strings=c("NA","#DIV/0!",""))
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
nzv <- nearZeroVar(inTrain)
inTrain <- inTrain[, -nzv]
## exclude the ID column from the training
inTrain<- inTrain[c(-1)]
## remove variables containing mostly NAs
theNAs <- sapply(inTrain, function(x) mean(is.na(x))) > 0.80
inTrain <- inTrain[, theNAs==F]
library(caret)
library(rattle)
library(rpart)
set.seed(4545)
trainData <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testData <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainData), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testData), na.strings=c("NA","#DIV/0!",""))
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
theTraining <- training[inTrain, ]
dim(theTraining)
theTesting <- training[-inTrain, ]
dim(theTesting)
nzv <- nearZeroVar(theTraining)
theTraining <- theTraining[, -nzv]
## exclude the ID column from the training
theTraining<- theTraining[c(-1)]
## remove variables containing mostly NAs
theNAs <- sapply(theTraining, function(x) mean(is.na(x))) > 0.80
theTraining <- theTraining[, theNAs==F]
nzv <- nearZeroVar(theTesting)
theTesting <- theTesting[, -nzv]
## exclude the ID column from the training
theTesting<- theTesting[c(-1)]
## remove variables containing mostly NAs
theNAs <- sapply(theTesting, function(x) mean(is.na(x))) > 0.80
theTesting <- theTesting[, theNAs==F]
View(theTesting)
modelFit <- train(classe ~ ., method="rpart", data=theTraining)
print(modelFit$finalModel)
fancyRpartPlot(modelFit$finalModel)
fitControl <- trainControl(method="cv", number=3, verboseIter=F)
fit <- train(classe ~ ., method="rf", trControl=fitControl, data=theTraining)
print(fit$finalModel)
fancyRpartPlot(fit$finalModel)
library(caret)
library(rattle)
library(rpart)
dim(theTraining)
print(modelFit$finalModel)
fancyRpartPlot(modelFit$finalModel)
print(fit$finalModel)
fancyRpartPlot(fit$finalModel)
fancyRpartPlot(fit$finalModel)
for (i in 1:length(testing) ) {
for(j in 1:length(theTraining)) {
if( length( grep(names(theTraining[i]), names(testing)[j]) ) ==1)  {
class(testing[j]) <- class(theTraining[i])
}
}
}
for (i in 1:length(theTesting) ) {
for(j in 1:length(theTraining)) {
if( length( grep(names(theTraining[i]), names(theTesting)[j]) ) ==1)  {
class(theTesting[j]) <- class(theTraining[i])
}
}
}
modelFit <- train(classe ~ ., method="rpart", data=theTraining)
print(modelFit$finalModel)
fancyRpartPlot(modelFit$finalModel)
fitControl <- trainControl(method="cv", number=3, verboseIter=F)
fit <- train(classe ~ ., method ="rf", trControl=fitControl, data=theTraining)
print(fit$finalModel)
fancyRpartPlot(fit$finalModel)
modelFit <- rpart(classe ~ ., data=myTraining, method="class")
modelFit <- rpart(classe ~ ., data=theTraining, method="class")
print(modelFit$finalModel)
fancyRpartPlot(modelFit$finalModel)
source('~/.active-rstudio-document')
cleanFirst <- colnames(theTraining)
cleanSecond <- colnames(theTraining[, -58]) #already with classe column removed
theTesting <- theTesting[cleanFirst]
testing <- testing[cleanSecond]
## coerce data into same data type
for (i in 1:length(testing) ) {
for(j in 1:length(theTraining)) {
if( length( grep(names(theTraining[i]), names(testing)[j]) ) ==1)  {
class(testing[j]) <- class(theTraining[i])
}
}
}
#And to make sure Coertion really worked, simple smart ass technique:
testing <- rbind(theTraining[2, -58] , testing) #note row 2 does not mean anything, this will be removed right.. now:
testing <- testing[-1,]
modelFit <- rpart(classe ~ ., data=theTraining, method="class")
## modelFit <- train(classe ~ ., method="rpart", data=theTraining)
print(modelFit$finalModel)
fancyRpartPlot(modelFit$finalModel)
modelFit <- train(classe ~ ., method="rpart", data=theTraining)
print(modelFit$finalModel)
fancyRpartPlot(modelFit$finalModel)
prediction1 <- predict(modelFit, theTesting, type = "class")
prediction1 <- predict(modelFit, theTesting, type = "raw")
confusionMatrix(prediction1, theTesting$classe)
fitControl <- trainControl(method="cv", number=3, verboseIter=F)
fit <- train(classe ~ ., method ="rf", trControl=fitControl, data=theTraining)
print(fit$finalModel)
fancyRpartPlot(fit$finalModel)
fit <- randomForest(classe ~. , data=theTraining)
print(fit$finalModel)
print((fit$finalModel))
fancyRpartPlot(fit$finalModel)
fit <- train(classe ~ ., method ="rf", data=theTraining)
fitControl <- trainControl(method="cv", number=3, verboseIter=F)
fit <- train(classe ~ ., method ="rf", trControl=fitControl, data=theTraining)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
xnames <- colnames(concrete)[1:8]
featurePlot(x=training[, xnames], y=training$CompressiveStrength, plot="pairs")
index <- seq_along(1:nrow(training))
ggplot(data=training, aes(x=index, y=CompressiveStrength)) + geom_point() +
theme_bw()
# Step-like pattern -> 4 categories
library(Hmisc)
cutCompressiveStrength <- cut2(training$CompressiveStrength, g=4)
summary(cutCompressiveStrength)
ggplot(data=training, aes(y=index, x=cutCompressiveStrength)) +
geom_boxplot() + geom_jitter(col="blue") + theme_bw()
library(plyr)
splitOn <- cut2(training$Age, g=4)
splitOn <- mapvalues(splitOn,
from=levels(factor(splitOn)),
to=c("red", "blue", "yellow", "green"))
plot(training$CompressiveStrength, col=splitOn)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(Superplasticizer, data=training) # OR
ggplot(data=training, aes(x=Superplasticizer)) + geom_histogram() + theme_bw()
ss <- training[,grep('^IL', x = names(training) )]
preProc <- preProcess(ss, method='pca', thresh=0.9,
outcome=training$diagnosis)
preProc$rotation # 7
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ss <- training[,grep('^IL', x = names(training) )]
preProc <- preProcess(ss, method='pca', thresh=0.9,
outcome=training$diagnosis)
preProc$rotation # 7
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL <- grep("^IL", colnames(training), value=TRUE)
ILpredictors <- predictors[, IL]
df <- data.frame(diagnosis, ILpredictors)
inTrain <- createDataPartition(df$diagnosis, p=3/4)[[1]]
training <- df[inTrain, ]
testing <- df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method="glm", data=training)
predictions <- predict(modelFit, newdata=testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
acc1 <- C1$overall[1]
acc1 # Non-PCA Accuracy: 0.65
modelFit2 <- train(training$diagnosis ~ .,
method="glm",
preProcess="pca",
data=training,
trControl=trainControl(preProcOptions=list(thresh=0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit2, testing))
print(C2)
acc2 <- C2$overall[1]
acc2 # PCA Accuracy: 0.72
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
data <- segmentationOriginal
set.seed(125)
inTrain <- data$Case == "Train"
trainData <- data[inTrain, ]
testData <- data[!inTrain, ]
cartModel <- train(Class ~ ., data=trainData, method="rpart")
cartModel$finalModel
plot(cartModel$finalModel, uniform=T)
text(cartModel$finalModel, cex=0.8)
library(pgmm)
data(olive)
olive = olive[,-1]
dim(olive)
treeModel <- train(Area ~ ., data=olive, method="rpart2")
treeModel
newdata <- as.data.frame(t(colMeans(olive)))
predict(treeModel, newdata) # 2.875
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train <- sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA <- SAheart[train,]
testSA <- SAheart[-train,]
set.seed(13234)
logitModel <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=trainSA, method="glm",
family="binomial")
logitModel
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predictTrain <- predict(logitModel, trainSA)
predictTest <- predict(logitModel, testSA)
missClass(trainSA$chd, predictTrain) # 0.2727273
missClass(testSA$chd, predictTest) # 0.3116883
data(vowel.train)
data(vowel.test)
head(vowel.train)
head(vowel.test)
dim(vowel.train) # 528  11
dim(vowel.test) # 462  11
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
library(caret)
order(varImp(modelRf), decreasing=T)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
View(segmentationOriginal)
data <- segmentationOriginal
set.seed(125)
inTrain <- data$Case == "Train"
trainData <- data[inTrain, ]
testData <- data[!inTrain, ]
cartModel <- train(Class ~ ., data=trainData, method="rpart")
cartModel$finalModel
plot(cartModel$finalModel, uniform=T)
text(cartModel$finalModel, cex=0.8)
plot(cartModel$finalModel, uniform=T)
text(cartModel$finalModel, cex=0.6)
text(cartModel$finalModel, cex=0.)
plot(cartModel$finalModel, uniform=T)
text(cartModel$finalModel, cex=0.)
library(pgmm)
data(olive)
olive = olive[,-1]
dim(olive)
head(olive)
treeModel <- train(Area ~ ., data=olive, method="rpart2")
treeModel
View(olive)
newdata <- as.data.frame(t(colMeans(olive)))
predict(treeModel, newdata) # 2.875
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
logitModel <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=trainSA, method="glm",
family="binomial")
logitModel
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predictTrain <- predict(logitModel, trainSA)
predictTest <- predict(logitModel, testSA)
missClass(trainSA$chd, predictTrain) # 0.2727273
missClass(testSA$chd, predictTest) # 0.3116883
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train)
head(vowel.test)
dim(vowel.train) # 528  11
dim(vowel.test) # 462  11
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
library(caret)
order(varImp(modelRf), decreasing=T)
library(caret)
library(rattle)
library(rpart)
set.seed(9876)
pml.training <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
pml.testing <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(pml.training), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(pml.testing), na.strings=c("NA","#DIV/0!",""))
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
theTraining <- training[inTrain, ]
dim(theTraining)
theTesting <- training[-inTrain, ]
dim(theTesting)
## remove near zero variables
nzv <- nearZeroVar(theTraining)
theTraining <- theTraining[, -nzv]
## exclude the first ID column from the training
theTraining<- theTraining[c(-1)]
## remove variables containing mostly NAs
theNAs <- sapply(theTraining, function(x) mean(is.na(x))) > 0.90
theTraining <- theTraining[, theNAs==F]
## remove near zero variables
nzv <- nearZeroVar(theTesting)
theTesting <- theTesting[, -nzv]
## exclude the ID column from the training
theTesting<- theTesting[c(-1)]
## exclude the ID column from the testing
theTesting<- theTesting[c(-1)]
## remove variables containing mostly (90%) of NAs
theNAs <- sapply(theTesting, function(x) mean(is.na(x))) > 0.90
theTesting <- theTesting[, theNAs==F]
theTesting <- training[-inTrain, ]
dim(theTesting)
nzv <- nearZeroVar(theTesting)
theTesting <- theTesting[, -nzv]
## exclude the ID column from the testing
theTesting<- theTesting[c(-1)]
## remove variables containing mostly (90%) of NAs
theNAs <- sapply(theTesting, function(x) mean(is.na(x))) > 0.90
theTesting <- theTesting[, theNAs==F]
## coerce data into same data type
for (i in 1:length(theTesting) ) {
for(j in 1:length(theTraining)) {
if( length( grep(names(theTraining[i]), names(theTesting)[j]) ) ==1)  {
class(theTesting[j]) <- class(theTraining[i])
}
}
}
View(theTraining)
plot(theTraining$row.names, col=classe)
plot(theTraining$user_name, col=classe)
plot(theTraining$user_name, col="classe")
plot(theTraining$user_name, col=theTraining$classe)
plot(theTraining$classe, col=theTraining$user_name)
runExample("03_reactivity")
install.packages("googleVis")
library(googleVis)
help('gvisMotionChart')
data(Fruits)
Fruits
M <- gvisMotionChart(Fruits, idvar="Fruit", timevar="Year")
str(M)
M$type
M$chartid
print(M, tag='header')
names(M$html$chart)
print(M, tag='chart')
plot(M)
shiny::runApp('Documents/coursera/DevelopingDataProduct/courses/09_DevelopingDataProducts/shiny/inputApp')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
100/3
100/10^2
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
ht < 155
ht <- 155
floor(ht/100)
ht/100
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
shiny::runApp('Documents/coursera/DevelopingDataProduct/week3/project/bmi')
setwd("~/Documents/coursera/DevelopingDataProduct/week3/project/bmi")
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
